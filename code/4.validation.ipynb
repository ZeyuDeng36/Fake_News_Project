{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Validation and cross-domain performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack, save_npz\n",
    "simple_BOW = np.load('../Simple_995_BBC.npz', allow_pickle=True)\n",
    "simple_ONEHOT = np.load('../Simple_995.npz', allow_pickle=True)\n",
    "advanced = np.load(\"../advanced_features.npz\", allow_pickle=True)\n",
    "liar_TFIDF = np.load(\"../LIAR_TFIDF.npz\", allow_pickle=True)\n",
    "liar_BOW = np.load(\"../LIAR_BOW.npz\", allow_pickle=True)\n",
    "liar_ONEHOT = np.load(\"../LIAR_ONEHOT.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of simple model with logistic regression and one-hot encoding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.54      0.96      0.70     41607\n",
      "           0       0.86      0.22      0.35     42919\n",
      "\n",
      "    accuracy                           0.59     84526\n",
      "   macro avg       0.70      0.59      0.52     84526\n",
      "weighted avg       0.71      0.59      0.52     84526\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                  40141                   1466\n",
      "True \"fake news\"                  33529                   9390\n",
      "Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      1.00      0.52      3638\n",
      "           0       0.00      0.00      0.00      6601\n",
      "\n",
      "    accuracy                           0.36     10239\n",
      "   macro avg       0.18      0.50      0.26     10239\n",
      "weighted avg       0.13      0.36      0.19     10239\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                   3638                      0\n",
      "True \"fake news\"                   6601                      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyu/PythonEnvironments/general/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/zeyu/PythonEnvironments/general/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/zeyu/PythonEnvironments/general/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "with open(\"../simple_model_ONEHOT.pkl\",'rb') as f:\n",
    "    simple_model = pickle.load(f)\n",
    "\n",
    "#load features\n",
    "X_test = simple_ONEHOT['X_test_content_ONEHOT'].item()\n",
    "Y_test = simple_ONEHOT['Y_test'].ravel()\n",
    "X_test_LIAR = liar_ONEHOT['X_test'].item()\n",
    "Y_test_LIAR=liar_ONEHOT['Y_test'].ravel()\n",
    "\n",
    "#validate model\n",
    "Y_pred = simple_model.predict(X_test)\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding:\")\n",
    "print(classification_report(Y_test, Y_pred, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test, Y_pred, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n",
    "#LIAR\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\")\n",
    "Y_pred_LIAR = simple_model.predict(X_test_LIAR)\n",
    "print(classification_report(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of simple model with logistic regression and one-hot encoding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.85      0.87     42060\n",
      "           0       0.86      0.90      0.88     43036\n",
      "\n",
      "    accuracy                           0.87     85096\n",
      "   macro avg       0.87      0.87      0.87     85096\n",
      "weighted avg       0.87      0.87      0.87     85096\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                  35673                   6387\n",
      "True \"fake news\"                   4434                  38602\n",
      "Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.38      0.07      0.12      3638\n",
      "           0       0.65      0.94      0.77      6601\n",
      "\n",
      "    accuracy                           0.63     10239\n",
      "   macro avg       0.51      0.50      0.44     10239\n",
      "weighted avg       0.55      0.63      0.53     10239\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                    247                   3391\n",
      "True \"fake news\"                    405                   6196\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "with open(\"../simple_model_BOW.pkl\",'rb') as f:\n",
    "    simple_model = pickle.load(f)\n",
    "\n",
    "#load features\n",
    "X_test = simple_BOW['X_test'].item()\n",
    "Y_test = simple_BOW['Y_test'].ravel()\n",
    "X_test_LIAR = liar_BOW['X_test'].item()\n",
    "Y_test_LIAR=liar_BOW['Y_test'].ravel()\n",
    "\n",
    "#validate model\n",
    "Y_pred = simple_model.predict(X_test)\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding:\")\n",
    "print(classification_report(Y_test, Y_pred, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test, Y_pred, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n",
    "#LIAR\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\")\n",
    "Y_pred_LIAR = simple_model.predict(X_test_LIAR)\n",
    "print(classification_report(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of simple model with logistic regression and one-hot encoding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.81      0.82     42060\n",
      "           0       0.82      0.84      0.83     43036\n",
      "\n",
      "    accuracy                           0.83     85096\n",
      "   macro avg       0.83      0.83      0.83     85096\n",
      "weighted avg       0.83      0.83      0.83     85096\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                  34218                   7842\n",
      "True \"fake news\"                   6924                  36112\n",
      "Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.43      0.09      0.15      3638\n",
      "           0       0.65      0.93      0.77      6601\n",
      "\n",
      "    accuracy                           0.63     10239\n",
      "   macro avg       0.54      0.51      0.46     10239\n",
      "weighted avg       0.57      0.63      0.55     10239\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                    341                   3297\n",
      "True \"fake news\"                    460                   6141\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"../advanced_model_NB.pkl\",'rb') as f:\n",
    "    advanced_model_NB = pickle.load(f)\n",
    "\n",
    "#load features\n",
    "X_test = advanced['X_test'].item()\n",
    "Y_test = advanced['Y_test'].ravel()\n",
    "X_test_LIAR = liar_TFIDF['X_test'].item()\n",
    "Y_test_LIAR=liar_TFIDF['Y_test'].ravel()\n",
    "\n",
    "#validate model\n",
    "Y_pred = advanced_model_NB.predict(X_test)\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding:\")\n",
    "print(classification_report(Y_test, Y_pred, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test, Y_pred, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n",
    "#LIAR\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\")\n",
    "Y_pred_LIAR = advanced_model_NB.predict(X_test_LIAR)\n",
    "print(classification_report(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of simple model with logistic regression and one-hot encoding:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.89      0.87      0.88     42060\n",
      "           0       0.88      0.89      0.89     43036\n",
      "\n",
      "    accuracy                           0.88     85096\n",
      "   macro avg       0.88      0.88      0.88     85096\n",
      "weighted avg       0.88      0.88      0.88     85096\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                  36707                   5353\n",
      "True \"fake news\"                   4554                  38482\n",
      "Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.03      0.05      3638\n",
      "           0       0.65      0.98      0.78      6601\n",
      "\n",
      "    accuracy                           0.64     10239\n",
      "   macro avg       0.53      0.50      0.41     10239\n",
      "weighted avg       0.56      0.64      0.52     10239\n",
      "\n",
      "                  Predicted \"real news\"  Predicted \"fake news\"\n",
      "True \"real news\"                     95                   3543\n",
      "True \"fake news\"                    138                   6463\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "\n",
    "with open(\"../advanced_model_SVC.pkl\",'rb') as f:\n",
    "    advanced_model_SVC = pickle.load(f)\n",
    "\n",
    "#load features\n",
    "X_test = advanced['X_test'].item()\n",
    "Y_test = advanced['Y_test'].ravel()\n",
    "X_test_LIAR = liar_TFIDF['X_test'].item()\n",
    "Y_test_LIAR=liar_TFIDF['Y_test'].ravel()\n",
    "\n",
    "#validate model\n",
    "Y_pred = advanced_model_SVC.predict(X_test)\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding:\")\n",
    "print(classification_report(Y_test, Y_pred, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test, Y_pred, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n",
    "#LIAR\n",
    "print(\"Evaluation of simple model with logistic regression and one-hot encoding on LIAR dataset:\")\n",
    "Y_pred_LIAR = advanced_model_SVC.predict(X_test_LIAR)\n",
    "print(classification_report(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]))\n",
    "df = pd.DataFrame(confusion_matrix(Y_test_LIAR, Y_pred_LIAR, labels=[1,0]), index=['True \"real news\"','True \"fake news\"'], columns=['Predicted \"real news\"','Predicted \"fake news\"'])\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
