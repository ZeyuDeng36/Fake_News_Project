{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: advanced model\n",
    "\n",
    "Many different methods have been tried for the advanced model, here are the ones that yielded meaningful results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack, save_npz\n",
    "data = np.load(\"../advanced_features.npz\", allow_pickle=True)\n",
    "X_train = data['X_train'].item()\n",
    "X_val= data['X_val'].item()\n",
    "Y_train = data['Y_train'].ravel()\n",
    "Y_val = data['Y_val'].ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naive bayes with tf-idf:\n",
    "\n",
    "Using multinominal naive bayes (the variant that incorporates word frequency features) in conjunction with tf-idf encoding. Yields relatively poorer results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8306951054703566\n",
      "Precision: 0.8352561144439317\n",
      "Recall: 0.8185366782501071\n",
      "F1 score: 0.8268118816642024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyu/PythonEnvironments/general/lib/python3.9/site-packages/sklearn/naive_bayes.py:890: RuntimeWarning: divide by zero encountered in log\n",
      "  self.feature_log_prob_ = np.log(smoothed_fc) - np.log(\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "model = MultinomialNB(alpha=0,force_alpha=True)\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred = model.predict(X_val)\n",
    "print(\"Accuracy:\",accuracy_score(Y_val,Y_pred))\n",
    "print(\"Precision:\",precision_score(Y_val,Y_pred,average=\"binary\"))\n",
    "print(\"Recall:\",recall_score(Y_val,Y_pred,average=\"binary\"))\n",
    "print(\"F1 score:\",f1_score(Y_val,Y_pred,average=\"binary\"))\n",
    "\n",
    "with open(\"../advanced_model_NB.pkl\",'wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "\n",
    "del model,Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### support vector machine with tf-idf:\n",
    "\n",
    "This is the complex model we have settled with, as it produces the best results out of all tested models. \n",
    "\n",
    "The linearSVC() has trouble converging when fitting the dataset. From experimenting with hyperparameters, I have found that beyond around 100 iterations, the benchmarks no longer improve, and are maxed out at around 88 for everything. The most iterations tried is 1000 iterations. \n",
    "\n",
    "There is another module from sklearn, SVC(), which offers support vector machines using nonlinear kernels, which might create better results. However, SVC()'s time complexity scales at least quadratically with number of samples. therefore, since our dataset has close to a million samples, we will be using LinearSVC instead. \n",
    "\n",
    "Attempting to run the normal SVC(), even with fractions of the 995,000 dataset has resulted in hours of compiling with no results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with RBF Kernel Classification Report:\n",
      "Accuracy: 0.8823197602679358\n",
      "Precision: 0.8875781212150574\n",
      "Recall: 0.8721140572190222\n",
      "F1 score: 0.8797781406069919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeyu/PythonEnvironments/general/lib/python3.9/site-packages/sklearn/svm/_base.py:1237: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "\n",
    "model1 = LinearSVC(dual=\"auto\",tol=1e-3, C=0.5,max_iter=300)\n",
    "model1.fit(X_train,Y_train)\n",
    "Y_pred = model1.predict(X_val)\n",
    "\n",
    "print(\"SVM with RBF Kernel Classification Report:\")\n",
    "print(\"Accuracy:\",accuracy_score(Y_val,Y_pred))\n",
    "print(\"Precision:\",precision_score(Y_val,Y_pred,average=\"binary\"))\n",
    "print(\"Recall:\",recall_score(Y_val,Y_pred,average=\"binary\"))\n",
    "print(\"F1 score:\",f1_score(Y_val,Y_pred,average=\"binary\"))\n",
    "\n",
    "with open(\"../advanced_model_SVC.pkl\",'wb') as f:\n",
    "    pickle.dump(model1,f)\n",
    "\n",
    "del Y_pred, model1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
